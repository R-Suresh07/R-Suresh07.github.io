---
layout: about
title: about
permalink: /
subtitle: Lead AI Research Engineer | VFS Global

profile:
  align: right
  image: profile.jpeg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>   New Delhi, India</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I build AI systems at VFS Global that process thousands of documents daily across visa applications for 110+ countries. The work sits at the intersection of production engineering and research, where systems need to be both highly reliable and honest about their limitations.

The problems I run into building these systems don't have solid solutions yet. When processing critical documents at scale, vision-language models need to not only extract information accurately but also know when they're uncertain. Existing approaches fall short, so I've been exploring ways to make AI systems in the vision domain more grounded.

I'm particularly interested in how reasoning models differ from instruct models when it comes to uncertainty, and whether we can build better frameworks for detecting hallucination versus uncertainty. Currently wrapping up my B.Sc. in Programming & Data Science from IIT Madras and working on papers about VLM calibration.

Always happy to chat about uncertainty quantification, VLMs, or anything at the intersection of production ML and research.

**Research interests:** Uncertainty quantification, vision-language models, hallucination detection, epistemic uncertainty in agentic systems